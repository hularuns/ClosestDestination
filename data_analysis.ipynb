{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import folium\n",
    "from folium.features import GeoJsonPopup\n",
    "from folium.plugins import Search\n",
    "import branca.colormap as cm\n",
    "import json\n",
    "\n",
    "#project specific packages\n",
    "\n",
    "from services import network_bands, batch_csv, census_merge, pandas_aux as pdaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------SERVICE AREA AND BAND CREATION---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first section will focus on leveraging the use of the functions found within <u>network_bands.py</u>, which will create a networkx graph resulting in the creation of service areas and finally service bands which are dissolved and differenced multipolygons of the service areas.\n",
    "\n",
    "Initially load road network data into base_road_path.\n",
    "\n",
    "Then create the road network using the <b>load_osm_network()</b> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set base directory for data file paths.\n",
    "base_dir = os.getcwd()\n",
    "# create network graph and edges.\n",
    "base_road_path = f'{base_dir}\\\\testEnvironment\\\\Data\\\\belfast.osm.pbf'\n",
    "G, nodes, edges = network_bands.load_osm_network(file_path=base_road_path, network_type='driving', graph_type='networkx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load start locations to create service areas from and ensure in GeoDataFrame with CRS of 4326 if using NetworkX. If the start locations are in CSV format with separate X and Y columns for coordinates in any CRS, these can be converted to a GeoDataFrame using the <b>csv_to_gdf()</b> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start locations\n",
    "start_locations = pd.read_csv(f'{base_dir}\\\\testEnvironment\\\\Data\\\\libraries_belfast_2024.csv')\n",
    "print(start_locations.columns)\n",
    "#Ensure data is converted to a dataframe\n",
    "start_locations_gdf = network_bands.csv_to_gdf(csv = start_locations, x_col = 'X COORDINATE', y_col = 'Y COORDINATE', \n",
    "                                               input_crs = 29902, crs_conversion = 4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using <b>nearest_node_and_name()</b> create a dictionary of the nearest node on the network graph to each start location point. If no names are present in the dataset  or you wish to anonymise the data, use the argument, <b>anon_name = True</b> to create random names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary of start locations and their nearest node on the network graph.\n",
    "start_locations_nearest_node = network_bands.nearest_node_and_name(graph=G, start_locations=start_locations_gdf,  \n",
    "                                                                   location_name = 'Static Library Name')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the service areas around the start locations on the network graph and then converting these to service bands.\n",
    "\n",
    "The <b>service_areas()</b> fuction creates polygons which are then dissolved and differenced by <b>service_bands()</b> to create non-overlapping multipolygons. The dissolving and differencing ensures that the polygons which are closer to the start location take precedence. For this to work,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the network areas and service areas - Considering making this into a Class with basic GUI, but for now fine as this.\n",
    "\n",
    "#input custom distances as a list.\n",
    "search_distances = [1000,2000,3000]\n",
    "#Create individual service_areas around start locations. alpha area of 500 quite good for Belfast and the density of points in this dataset\n",
    "service_areas = network_bands.service_areas(nearest_node_dict = start_locations_nearest_node, graph = G, \n",
    "                                                    search_distances = search_distances, alpha_value = 500, weight = 'length', \n",
    "                                                    save_output=True)\n",
    "#Create network service areas by dissolving and differencing polygons based on distance.\n",
    "service_bands = network_bands.service_bands(service_areas, dissolve_cat = 'distance',aggfunc = 'first', \n",
    "                                                            show_graph = True, save_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------DATA ANALYSIS EXAMPLE--------------------------------------------------------\n",
    "\n",
    "Using example NISRA Census 2021 data, example data can be manipulated and plotted using a variety of methods.\n",
    "This can be further extended with statistics.\n",
    "\n",
    "Using the data in testEnvironment/Data a basic population map is created using folium.\n",
    "\n",
    "- Load in the census data zones and filter to only include the location being analysed (Belfast)\n",
    "- Load in the pointer household dataset which has been randomised multiple times as to remove any commercial value.\n",
    "- Ensure all data is projected to CRS 4326.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the ancillary functions in census_merge, batch_csv and pandas_aux, example data analysis\n",
    "#Load in data zones from 2021  census\n",
    "#Ensure evrything's in 4326 for network analysis, probably can change it back to tm65.\n",
    "data_zones = gpd.read_file(f'{base_dir}\\\\testEnvironment\\\\Data\\\\DZ2021.shp')\n",
    "data_zones.to_crs(4326, inplace=True)\n",
    "#extract only belfast datazones\n",
    "belfast_zones = data_zones[data_zones['LGD2014_nm'] == 'Belfast']\n",
    "\n",
    "#Load in house data \n",
    "pointer = gpd.read_file(f'{base_dir}\\\\testEnvironment\\\\Data\\\\pointer_randomised.shp')\n",
    "#create uuid, might be useful, not entirely necessary.\n",
    "pointer['uuid'] = pointer.apply(lambda i: uuid.uuid4(), axis=1)\n",
    "#ensure all are in the same crs (should be 4326 or 3857)\n",
    "pointer.to_crs(4326, inplace=True)\n",
    "belfast_zones.to_crs(pointer.crs, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial join the data zones with the pointer dataset to calculate how many households (points) within each data zone. \n",
    "\n",
    "Group by datazone and .count() the points, creating a new dataframe, merging this back to the data zone dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a spatial join of pointer households and datazones in Belfast to calculate households in each datazone\n",
    "joined_gdf = gpd.sjoin(pointer, belfast_zones, how='left', predicate='intersects' )\n",
    "#number of points found within each datazone\n",
    "datazone_pointer_count = joined_gdf.groupby('DZ2021_cd')['DZ2021_cd'].count().rename('actual_households').reset_index()\n",
    "belfast_zones = pd.merge(belfast_zones, datazone_pointer_count, how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in census data, this can be batch loaded using the <b>batch_csv_read()</b> function. Once loaded, rename any columns before commencing further; it may also be necessary to ensure column names are all upper or lower case as this can help avoid any issues later down the line.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Census data, file_paths in file_paths.\n",
    "file_paths = [\n",
    "    '/testEnvironment/Data/census_data/ni-2021-usual-residents.csv',\n",
    "    '/testEnvironment/Data/census_data/ni-2021-households.csv',\n",
    "    '/testEnvironment/Data/census_data/ni-2021-employment-deprivation.csv'\n",
    "]\n",
    "#load all defined csvs\n",
    "loaded_csv = batch_csv.batch_csv_read(file_paths)\n",
    "\n",
    "#check data is loaded loaded\n",
    "print(loaded_csv.keys())\n",
    "\n",
    "#force rename to maintain consistency of important join value column.\n",
    "loaded_csv['ni-2021-employment-deprivation'].rename(columns={'Census 2021 Data Zone Code':'Geography code',\n",
    "                                                             'Count':'employment_deprivation_count'}, inplace=True)\n",
    "\n",
    "#Data can have irregular capitalisation, avoids this bug by forcing lower case. Some are 'Geography Code', 'geography Code' etc.\n",
    "# Need to incorporate this properly into function \n",
    "for key, df in loaded_csv.items():\n",
    "    df.columns = df.columns.str.lower()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the census data together based on the 'geography code', which can be the DataZone code, SuperDataZone etc using the join_census_csv() function. Drop any extraneous columns which may not be necessary if you wish to maintain a tidier DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Join the CSV data together based on common ID column such as geography code in NISRA census 2021 data.\n",
    "joined_census_data = census_merge.join_census_csv(loaded_csv, 'geography code',  drop=True,join_type='left')\n",
    "#dropping some extraneous columns as they are not needed and clutter the dataset\n",
    "joined_census_data.drop(columns=['household deprivation (employment) code','household deprivation (employment) label'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the data zone polygons with a Pandas merge with the joined census data, in this case with the DataZone code. Assigning suffixes allows for the subsequent <b>drop_dupe_cols()</b> function to intelligently drop the right hand column, retaining the left hand column where there is a duplication. This also renames the left column ensuring that it there is no suffix appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data zones with the loaded census data.\n",
    "belfast_zones_census = pd.merge(belfast_zones, joined_census_data, left_on='DZ2021_cd', right_on='geography code', \n",
    "                                how='left', suffixes=('_left', '_right'))\n",
    "\n",
    "# Drop the duplicate columns from the merged dataframe\n",
    "census_merge.drop_dupe_cols(belfast_zones_census, ('_left', '_right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate your statistics based upon the joined household count data and joined census data. Not all statistics calculated here were used in the end map result, however the extent of this is shown to show how extensive this can be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate CENSUS METRICS PER HOUSE in pointer data\n",
    "#Need to force these to numeric. Ensure coerce for any nulls\n",
    "belfast_zones_census['all households'] = pd.to_numeric(belfast_zones_census['all households'], errors = 'coerce')\n",
    "belfast_zones_census['all usual residents'] = pd.to_numeric(belfast_zones_census['all usual residents'], errors = 'coerce')\n",
    "\n",
    "## Calculate additional metrics. Average resident per house etc.\n",
    "\n",
    "#average residents per household\n",
    "belfast_zones_census['avg_resi_house'] = (belfast_zones_census['all usual residents'] / belfast_zones_census['actual_households'])\n",
    "#actual residents based off pointer\n",
    "belfast_zones_census['actual_total_residents'] = (belfast_zones_census['avg_resi_house'] * belfast_zones_census['actual_households'])\n",
    "#average number of employment deprived people per household. - Super relevant for this analysis.\n",
    "belfast_zones_census['avg_emp_dep_per_house'] = (belfast_zones_census['employment_deprivation_count'] / belfast_zones_census['actual_households'])*belfast_zones_census['avg_resi_house']\n",
    "#average number of employmenet deprived people per resident.\n",
    "belfast_zones_census['avg_emp_dep_per_capita'] = (belfast_zones_census['employment_deprivation_count'] / belfast_zones_census['all usual residents'])*belfast_zones_census['avg_resi_house']\n",
    "\n",
    "#Force to gdf, currently will be a panda series\n",
    "belfast_zones_census = gpd.GeoDataFrame(belfast_zones_census, crs = 4326)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the census data is is homogenous across each DataZone and does not consider the impact of distance to the nearest library. \n",
    "\n",
    "This is similar to the step earlier which was used to calculate the number of points within each DataZone.\n",
    "\n",
    "- Spatial join to identify which househould point is situated within each network_band.\n",
    "- This data is then spatially joined with the DataZone data.\n",
    "- This is grouped by DataZone code and unstacked, which create separate columns. \n",
    "- The unstacked column names are then assigned a prefix, in this case, households_ using the <b>append_col_prefix()</b> function.\n",
    "- Remove any NaN values with <b>fill_na_with_zero()</b> function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial join to find which network band each household falls into\n",
    "households_with_contour = gpd.sjoin(pointer, service_bands, how=\"left\", predicate=\"within\")\n",
    "households_with_contour = households_with_contour.drop(columns='index_right').reset_index(drop=True)\n",
    "\n",
    "# spatial to join data zone data to each household\n",
    "households_with_zones = gpd.sjoin(households_with_contour, belfast_zones_census, how=\"left\", predicate=\"within\").drop(columns='index_right').reset_index(drop=True)\n",
    "\n",
    "# Group by census zone and distance and then count. Unstacks the distance columns to create separate columns for each distance.\n",
    "household_counts = households_with_zones.groupby(['DZ2021_cd', 'distance']).size().unstack(fill_value=0)\n",
    "\n",
    "#join this back to the belfast_census_zones to add the counts as new columns\n",
    "belfast_zones_census = belfast_zones_census.merge(household_counts, on='DZ2021_cd', how='left')\n",
    "\n",
    "# append column name to unstacked columns\n",
    "belfast_zones_census = pdaux.append_col_prefix(belfast_zones_census, [1000, 2000,3000], prefix='households')        \n",
    "\n",
    "#replace NaNs with 0s\n",
    "pdaux.fill_na_with_zero(belfast_zones_census, ['households_1000','households_2000','households_3000'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is plotted with folium, the calculated households within each network band per datazone is shown in a popup for each datazone. Datazones can be searched for in this example by DZ2021_cd and their Name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a folium map - This part's quite manual.\n",
    "#turn this into a bunch of functions to get this smaller and more refined down the line.\n",
    "#Numbers will be off due to randomisation of pointer dataset.\n",
    "belfast_census_data_geojson = json.loads(belfast_zones_census.to_json())\n",
    "service_bands_geojson = json.loads(service_bands.to_json())\n",
    "\n",
    "# Create the Folium map centered around the average coordinates of datazone geometries, can ignore warning\n",
    "map_center = belfast_zones_census.geometry.centroid.unary_union.centroid\n",
    "m = folium.Map(location=[map_center.y, map_center.x], zoom_start=12)\n",
    "\n",
    "###could turn this network_service_areas_style creation into a larger func\n",
    "distances = [1000, 2000, 3000] \n",
    "colours = ['green', 'orange', 'red']\n",
    "color_map = cm.LinearColormap(\n",
    "    colors=colours,\n",
    "    vmin=min(distances),\n",
    "    vmax=max(distances),\n",
    "    caption='Distance to Network Contours'\n",
    ")\n",
    "distance_colours = {dist: colour for dist, colour in zip(distances, colours)}\n",
    "def network_service_areas_style(feature):\n",
    "    \"\"\"Apply styles based on the distance attribute.\"\"\"\n",
    "    distance = feature['properties']['distance']\n",
    "    return {\n",
    "        'color': distance_colours.get(distance, 'gray'),\n",
    "        'weight': 2,\n",
    "        'opacity': 0.8,\n",
    "        'fillColor': distance_colours.get(distance, 'gray'), \n",
    "        'fillOpacity': 0.5\n",
    "    }\n",
    "\n",
    "#basic styling for the polygons\n",
    "def basic_poly_styling(feature):\n",
    "    return {\n",
    "        'color': 'black',\n",
    "        'weight':1,\n",
    "        'fillOpacity': 0.1\n",
    "    }\n",
    "\n",
    "#defines the highlight colour\n",
    "def highlight_function(feature):\n",
    "    return {\n",
    "        'color': 'yellow',\n",
    "        'weight': 2,\n",
    "        'fillOpacity':0.2\n",
    "    }\n",
    "network_service_bands_layer = folium.GeoJson(\n",
    "    service_bands_geojson,\n",
    "    style_function=network_service_areas_style,\n",
    "    name = 'Search Area Bands',\n",
    "    tooltip=folium.GeoJsonTooltip(\n",
    "        fields=['distance'],\n",
    "        aliases=['Distance:'],\n",
    "        localize = True\n",
    "    )\n",
    ")\n",
    "network_service_bands_layer.add_to(m)\n",
    "\n",
    "\n",
    "#census zone layer\n",
    "data_zone_layer = folium.GeoJson(\n",
    "    belfast_census_data_geojson,\n",
    "    name='Houses within 1000m',\n",
    "    style_function=basic_poly_styling,\n",
    "    highlight_function=highlight_function,\n",
    "\n",
    "    popup = GeoJsonPopup(\n",
    "        fields=['DZ2021_cd', 'DZ2021_nm', 'actual_households', 'households_1000','households_2000','households_3000'],\n",
    "        aliases=['Data Zone:', 'Data Zone Name:', 'Households:', 'Households within 1km:', \n",
    "                'Households within 2km:', 'Households within 3km:'],\n",
    "        localize=True,\n",
    "        labels=True\n",
    "    )\n",
    ")\n",
    "data_zone_layer.add_to(m)\n",
    "#Search layer for datazone code\n",
    "search_dz_code = Search(\n",
    "    layer=data_zone_layer,\n",
    "    geom_type='Polygon',\n",
    "    placeholder='Search for Data Zone Code',\n",
    "    search_label='DZ2021_cd',\n",
    "    search_zoom=14,\n",
    "    position='topleft'\n",
    ")\n",
    "search_dz_code.add_to(m)\n",
    "\n",
    "#can search by name as well\n",
    "search_dz_name = Search(\n",
    "    layer=data_zone_layer,\n",
    "    geom_type='Polygon',\n",
    "    placeholder='Search for Data Zone Name',\n",
    "    search_label='DZ2021_nm',\n",
    "    search_zoom=14,\n",
    "    position='topleft'\n",
    ")\n",
    "search_dz_name.add_to(m)\n",
    "\n",
    "# layer control\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Save the map to an HTML file \n",
    "m.save('test.html', cdn_resources='cdn')\n",
    "\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netgeo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
