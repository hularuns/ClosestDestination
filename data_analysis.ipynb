{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrosm import OSM\n",
    "import osmnx as ox\n",
    "import network_bands\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://build.nisra.gov.uk/en/custom/data?d=HOUSEHOLD&v=DZ21&v=HH_LIFESTAGE_AGG15\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set base directory for data file paths.\n",
    "base_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network graph and edges.\n",
    "base_road_path = f'{base_dir}\\\\testEnvironment\\\\Data\\\\belfast_super_trimmed.osm.pbf'\n",
    "G, nodes, edges = network_bands.load_osm_network(file_path=base_road_path, network_type='driving', graph_type='networkx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start locations\n",
    "start_locations = pd.read_csv(f'{base_dir}\\\\testEnvironment\\\\Data\\\\libraries_belfast_2024.csv')\n",
    "\n",
    "#Ensure data is converted to a dataframe\n",
    "start_locations_gdf = network_bands.csv_to_gdf(start_locations, 'X COORDINATE', 'Y COORDINATE', 29902, 4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the network\n",
    "start_locations_nearest_node = network_bands.nearest_node_and_name(G, start_locations=start_locations_gdf,  location_name = 'Static Library Name')\n",
    "#Create service areas for each distance. Remember, these overlap.\n",
    "#input custom distances as a list.\n",
    "search_distances = [1000,2000,3000]\n",
    "#this will print ongoing progress.\n",
    "alpha_areas = network_bands.single_source_polygon(nearest_node_dict=start_locations_nearest_node, graph=G, search_distances=search_distances,\n",
    "                                                  alpha_value=500, weight = 'distance', progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pointer data\n",
    "pointer = gpd.read_file(f'{base_dir}\\\\testEnvironment\\\\Data\\\\pointer_trimmed_for_trimmed_library.shp')\n",
    "#Ensures that the pointer and start location CRS are the same (should be 4326 if using osm data)\n",
    "if pointer.crs != start_locations_gdf.crs:\n",
    "    pointer = pointer.to_crs(start_locations_gdf.crs)\n",
    "# assign each house a uuid - useful later down the line.\n",
    "pointer['uuid'] = pointer.apply(lambda index: uuid.uuid4(), axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in data zones from 2021 census\n",
    "data_zones = gpd.read_file(f'{base_dir}\\\\testEnvironment/Data/DZ2021.shp')\n",
    "#extract only belfast datazones\n",
    "belfast_zones = data_zones[data_zones['LGD2014_nm'] == 'Belfast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "\n",
    "edges.plot(ax=ax, zorder=2)\n",
    "pointer.plot(ax=ax, color='black', zorder = 12, markersize=2)\n",
    "start_locations_gdf.plot(ax=ax, color='red', zorder=13, markersize=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    '/testEnvironment/Data/census_data/ni-2021-usual-residents.csv',\n",
    "    '/testEnvironment/Data/census_data/ni-2021-households.csv',\n",
    "    '/testEnvironment/Data/census_data/ni-2021-employment-deprivation.csv'\n",
    "]\n",
    "\n",
    "#probs move this to services.\n",
    "def mass_csv_read(file_paths:list):\n",
    "    \"\"\" Read function to read all CSVs and place into a dictionary of dataframes for subsequent analysis and joining.\n",
    "    File paths should be from the parent folder onwards. Do not include C:/User etc.\n",
    "    Parameters:\n",
    "        file_paths (list): A list of file paths, each string should look like '/data/stored/here/mydata.csv'.\n",
    "    \"\"\"\n",
    "    base_dir = os.getcwd()\n",
    "    csv_loaded = {}\n",
    "    for file_path in file_paths:\n",
    "            filename = os.path.basename(file_path)\n",
    "            key = os.path.splitext(filename)[0]\n",
    "            csv_loaded[key] = pd.read_csv(base_dir+file_path)\n",
    "    return csv_loaded\n",
    "#extract each one from dataframe\n",
    "\n",
    "loaded_csv = mass_csv_read(file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check data is loaded loaded\n",
    "print(loaded_csv.keys())\n",
    "\n",
    "#force rename to maintain consistency of important join value column.\n",
    "loaded_csv['ni-2021-employment-deprivation'].rename(columns={'Census 2021 Data Zone Code':'Geography code'}, inplace=True)\n",
    "\n",
    "#OSNI data has irregular capitalisation. Some are 'Geography Code', 'geography Code' etc.\n",
    "for key, df in loaded_csv.items():\n",
    "    df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Likely move this function to services too.\n",
    "def join_ni_census(dict_of_df:dict, join_column:str, join_type='left'):\n",
    "    \"\"\" Join OSNI census data geographic code. Deletes duplicated. Ensure there are not any duplicate label names.\n",
    "    geography_code or whaterver the join column is should be returned as dropped from the right dataframe.\n",
    "    \n",
    "    Parameters: \n",
    "        dict_of_df (dict): dictionary of dataframes, a result of the mass_csv_read() function.\n",
    "        join_column (str): column name to join by.\n",
    "        join_type: type of join - SQL-like, see pd.merge() docs.\"\"\"\n",
    "    joined_df = next(iter(dict_of_df.values()))\n",
    "    columns_dropped = []\n",
    "    for key, df in loaded_csv.items():\n",
    "        \n",
    "        if df is not joined_df: #ensure it doesn't join self\n",
    "            #clean the data first. using .drop_duplicated() producted awkward column names. This way is cleaner.\n",
    "            columns_to_drop = []\n",
    "            for column in df.columns:\n",
    "                if column in joined_df.columns and column != join_column:\n",
    "                    columns_to_drop.append(column)\n",
    "            \n",
    "            df_trimmed = df.drop(columns=columns_to_drop)\n",
    "            columns_dropped.append(columns_to_drop)\n",
    "            joined_df = pd.merge(joined_df, df_trimmed, on=join_column, how=join_type)\n",
    "    print(f'The following columns were duplicates from the right join and not included: {columns_dropped}')\n",
    "    \n",
    "    return joined_df\n",
    "\n",
    "joined_census_data = join_ni_census(loaded_csv, 'geography code', 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_census_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netgeo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
